# ImplementaÃ§Ã£o do Lambda Ingestion Processor

## ğŸ“‹ Resumo da ImplementaÃ§Ã£o

Este documento detalha a implementaÃ§Ã£o do Lambda `ingestion_processor` que processa dados de telemetria do IoT Core e os salva no S3 com particionamento Hive.

## ğŸ”§ CÃ³digo Python Implementado

### **Arquivo:** `src/ingestion/ingestion_processor.py`

**Principais funcionalidades:**

1. **ExtraÃ§Ã£o do Tipo de Sensor:**
   ```python
   def extract_sensor_type_from_topic(mqtt_topic):
       # Extrai 'temperature' de 'industrial/machine/PUMP-A01/temperature'
       topic_parts = mqtt_topic.split('/')
       return topic_parts[-1]
   ```

2. **GeraÃ§Ã£o de Chave S3 com Particionamento Hive:**
   ```python
   def generate_s3_key(sensor_type, ingestion_time):
       # Formato: raw/year=2025/month=10/day=02/hour=03/temperature_reading_1760000000123.jsonl
       year = ingestion_time.strftime('%Y')
       month = ingestion_time.strftime('%m')
       day = ingestion_time.strftime('%d')
       hour = ingestion_time.strftime('%H')
       epoch_ms = int(ingestion_time.timestamp() * 1000)
       filename = f"{sensor_type}_reading_{epoch_ms}.jsonl"
       return f"{S3_PREFIX_ROOT}/year={year}/month={month}/day={day}/hour={hour}/{filename}"
   ```

3. **Salvamento no S3:**
   ```python
   def save_telemetry_to_s3(payload, s3_key):
       jsonl_content = json.dumps(payload, separators=(',', ':'))
       s3_client.put_object(
           Bucket=S3_BUCKET_NAME,
           Key=s3_key,
           Body=jsonl_content,
           ContentType='application/json',
           ServerSideEncryption='AES256'
       )
   ```

## ğŸ¯ Exemplo de ExecuÃ§Ã£o

### **Entrada:**
- **TÃ³pico:** `industrial/machine/FAN-B02/telemetry/vibration`
- **Payload:** `{"machine_id": "FAN-B02", "timestamp_utc": "2025-10-02T03:15:00Z", "vibration_rms": 5.8}`

### **Processamento:**
1. **Tipo de Sensor:** `vibration` (extraÃ­do do tÃ³pico)
2. **Timestamp de IngestÃ£o:** `2025-10-02 03:15:00 UTC`
3. **Chave S3:** `raw/year=2025/month=10/day=02/hour=03/vibration_reading_1760000000123.jsonl`

### **SaÃ­da:**
- **Arquivo S3:** `s3://meu-projeto-datalake/raw/year=2025/month=10/day=02/hour=03/vibration_reading_1760000000123.jsonl`
- **ConteÃºdo:** `{"machine_id": "FAN-B02", "timestamp_utc": "2025-10-02T03:15:00Z", "vibration_rms": 5.8, "ingestion_timestamp": "2025-10-02T03:15:00.123Z", "sensor_type": "vibration", "mqtt_topic": "industrial/machine/FAN-B02/telemetry/vibration"}`

## ğŸ” PermissÃµes IAM NecessÃ¡rias

### **Para a Role da Lambda `ingestion_processor`:**

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject"
      ],
      "Resource": "arn:aws:s3:::meu-projeto-datalake/*"
    }
  ]
}
```

**PermissÃµes implementadas no Terraform:**
- âœ… **`s3:PutObject`**: Para salvar arquivos no S3
- âœ… **Recurso especÃ­fico**: Apenas no bucket do Data Lake
- âœ… **PrincÃ­pio do menor privilÃ©gio**: Apenas as permissÃµes necessÃ¡rias

## ğŸŒ VariÃ¡veis de Ambiente

### **VariÃ¡veis Esperadas pelo CÃ³digo:**

| VariÃ¡vel | DescriÃ§Ã£o | Exemplo | Fonte Terraform |
|----------|-----------|---------|-----------------|
| `S3_BUCKET_NAME` | Nome do bucket S3 | `meu-projeto-datalake` | `aws_s3_bucket.data_lake.bucket` |
| `S3_PREFIX_ROOT` | Prefixo raiz no S3 | `raw` | ConfigurÃ¡vel via variÃ¡vel |

### **ConfiguraÃ§Ã£o no Terraform:**
```hcl
environment {
  variables = {
    S3_BUCKET_NAME = aws_s3_bucket.data_lake.bucket
    S3_PREFIX_ROOT = "raw"
  }
}
```

## ğŸ”„ Fluxo de Dados Implementado

```
IoT Core (MQTT) â†’ Lambda Ingestion Processor â†’ S3 (Particionado)
```

**Detalhamento:**
1. **IoT Core** publica telemetria nos tÃ³picos `industrial/machine/{machine_id}/telemetry/{sensor_type}`
2. **Regra IoT Core** captura mensagens e inclui o tÃ³pico: `SELECT *, topic() as mqtt_topic FROM 'industrial/machine/+/telemetry/+'`
3. **Lambda Ingestion** processa e salva no S3 com particionamento Hive
4. **S3** armazena arquivos JSON Lines particionados por data/hora

## ğŸ“Š Estrutura de Dados no S3

### **Particionamento Hive:**
```
s3://bucket/raw/
â”œâ”€â”€ year=2025/
â”‚   â”œâ”€â”€ month=01/
â”‚   â”‚   â”œâ”€â”€ day=15/
â”‚   â”‚   â”‚   â”œâ”€â”€ hour=10/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ temperature_reading_1737000000123.jsonl
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ vibration_reading_1737000000456.jsonl
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ hour=11/
â”‚   â”‚   â””â”€â”€ day=16/
â”‚   â””â”€â”€ month=02/
```

### **Formato dos Arquivos:**
- **ExtensÃ£o:** `.jsonl` (JSON Lines)
- **ConteÃºdo:** Uma linha por arquivo com payload JSON
- **Metadados:** Inclui `ingestion_timestamp`, `sensor_type`, `mqtt_topic`

## ğŸš€ ConfiguraÃ§Ã£o no Terraform

### **MudanÃ§as Implementadas:**

1. **Empacotamento AutomÃ¡tico:**
   ```hcl
   data "archive_file" "ingestion_zip" {
     type        = "zip"
     source_file = "${path.module}/../../src/ingestion/ingestion_processor.py"
     output_path = "${path.module}/ingestion.zip"
   }
   ```

2. **Lambda com CÃ³digo Real:**
   ```hcl
   resource "aws_lambda_function" "ingestion" {
     filename         = data.archive_file.ingestion_zip.output_path
     source_code_hash = data.archive_file.ingestion_zip.output_base64sha256
     handler          = "ingestion_processor.handler"
     # ...
   }
   ```

3. **Regra IoT Core Atualizada:**
   ```hcl
   resource "aws_iot_topic_rule" "telemetry_ingestion_rule" {
     sql = "SELECT *, topic() as mqtt_topic FROM 'industrial/machine/+/telemetry/+'"
     # ...
   }
   ```

## ğŸ§ª Teste da ImplementaÃ§Ã£o

### **1. Deploy da Infraestrutura:**
```bash
cd terraform
terraform init
terraform plan
terraform apply
```

### **2. Verificar Lambda:**
```bash
aws lambda get-function --function-name replyec-ingestion
```

### **3. Testar com Payload Simulado:**
```bash
aws lambda invoke --function-name replyec-ingestion \
  --payload '{"machine_id": "PUMP-A01", "timestamp_utc": "2025-10-02T03:15:00Z", "temperature_celsius": 75.4, "mqtt_topic": "industrial/machine/PUMP-A01/telemetry/temperature"}' \
  response.json
```

### **4. Verificar Arquivo no S3:**
```bash
aws s3 ls s3://replyec-data-lake-20250115/raw/ --recursive
```

## âš ï¸ Notas Importantes

- **CÃ³digo-Fonte**: Agora usa o arquivo real `ingestion_processor.py`
- **Auto-Update**: Lambda serÃ¡ atualizada automaticamente quando o cÃ³digo mudar
- **Particionamento**: Dados organizados por data/hora para consultas eficientes
- **Formato JSON Lines**: Facilita processamento posterior com ferramentas como Spark
- **Metadados**: Inclui informaÃ§Ãµes de ingestÃ£o para rastreabilidade

A implementaÃ§Ã£o estÃ¡ completa e pronta para processar dados de telemetria em tempo real! ğŸ‰
